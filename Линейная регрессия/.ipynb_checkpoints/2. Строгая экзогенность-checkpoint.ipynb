{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строгая экзогенность\n",
    "<br>\n",
    "- **Вопрос 1:** если в целевой функции две зависимых переменных, а в модели построена только одна, то насколько конкретно будет смещена оценка коэффициента перед переменной в модели? Рассмотрим два случая: когда имеется confounding-переменная (т.е. истинная причина, которая влияет на зависимую и независимую переменные), и когда имеется просто недоступная нам переменная, которая не влияет на имеющуюся у нас переменную, однако при этом её матожидание не равно нулю, а оттуда и матожидание шума получится ненулевое, то есть предположение о строгой экзогенности будет нарушено.\n",
    "\n",
    "- **Вопрос 2:** если в целевой функции $\\text{y}$ зависит от $\\text{X и X^2}$, а в модели - только от $\\text{X}$ (то есть $\\text{X^2}$ окажется в шуме), то насколько конкретно будет смещена оценка коэффициента перед переменной в модели?\n",
    "\n",
    "<br><br><br><hr>\n",
    "## 1. Наблюдение первое - confounding variable и дополнительная переменная\n",
    "Рассмотрим следующий случай. Пусть на основе имеющихся данных мы регрессируем Зарплату на Образование, и построенная нами модель имеет вид:\n",
    "\n",
    "$$\\text{Wages} = \\beta_0 + \\beta_1\\cdot\\text{Education} + \\varepsilon$$\n",
    "\n",
    "Однако в реальности отношение несколько иное:\n",
    "\n",
    "$$\\text{Wages} = \\beta_0 + \\beta_1\\cdot \\text{Education} + \\beta_2\\cdot\\text{Ability} + \\mu$$\n",
    "\n",
    "Способности в данном случае влияют на Образование и на Зарплату: чем выше Способности - тем больше Образование (более способные ученики чаще получают лучшее образование) и тем больше прогнозируемая Зарплата (более способные люди чаще зарабатывают больше). Между тем, Образование само по себе не очень сильно влияет на Зарплату: можно учиться долго и много, но зарабатывать мало, тогда как несколько менее образованный но более \"пробивной\" работник может подняться выше по карьерной лестнице. Легко показать, что есть матожидание Способностей ненулевое, то $\\mathsf{E}[\\varepsilon]\\neq 0$, то есть нарушается экзогенность. Рассмотрим эту ситуацию подробнее и обратим внимание на оценки коэффициентов Образования.\n",
    "\n",
    "<br><br><center>**Опыт 1. Confounding-переменная, влияет на X и y**</center>\n",
    "\n",
    "Введём следующие условия:\n",
    "\n",
    "**Условия:**\n",
    "1. Зависимая переменная регрессируется на одну независимую переменную.\n",
    "2. Присутствует скрытая переменная, влияющая как на х, так и на у.\n",
    "\n",
    "**Объект интереса:**\n",
    "- Оценка коэффициента $\\text{x}$ и её смещение - endgogeneity bias \n",
    "\n",
    "**Ожидание:**\n",
    "\n",
    "- ///"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konstantin/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 10000\n",
      "\u001b[1m  -- Сгенерирована целевая функция.\n",
      " \u001b[0m     Значения коэффициентов целевой функции:\n",
      "\t· β0 = 4.5 \n",
      "\t· β1 = 0.0 \n",
      "\t· β2 = 7.068557677023679\n",
      "    Корреляция между информативным и неинформативным признаками: 0.000971143435667\n",
      "    Корреляция между информативным признаком и y:                0.515213248558\n",
      "    Корреляция между неинформативным признаком и y:              0.0059826774821\n",
      "\u001b[1m \n",
      "\n",
      " -- Построена модель (на основании неинформативного признака). \u001b[0m\n",
      "    Оценки коэффициентов регрессии:\n",
      "\t· Оценка β0: 4.4483566349 \n",
      "\t· Оценка β1: 0.0829651933222\n"
     ]
    }
   ],
   "source": [
    "# General:\n",
    "import numpy as np\n",
    "# Graphics:\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "# ML:\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import make_regression\n",
    "FONT_BOLD, FONT_END = '\\033[1m', '\\033[0m'\n",
    "\n",
    "BIAS  = 4.5\n",
    "NOISE = 12\n",
    "POPULATION_SIZE = 10000\n",
    "print('Used', POPULATION_SIZE)\n",
    "\n",
    "\n",
    "# 1. Сгенерируем проблему регрессии с двумя независимыми переменными:\n",
    "X, y, real_coef = make_regression(n_samples=POPULATION_SIZE, n_features=2, n_informative=1, \n",
    "                                  coef=True, noise=NOISE, bias=BIAS)\n",
    "print(FONT_BOLD, ' -- Сгенерирована целевая функция.\\n', FONT_END, '    Значения коэффициентов целевой функции:')\n",
    "print('\\t· β0 =', BIAS, '\\n\\t· β1 =', real_coef.item(0), '\\n\\t· β2 =', real_coef.item(1))\n",
    "informative_feature_index = int(real_coef.item(0) == 0)\n",
    "informative_feature_coef  = max(real_coef.item(0), real_coef.item(1))\n",
    "\n",
    "# # 2. Запишем коэффициент корреляции Пирсона между информативным и неинформативным признаками:\n",
    "# inter_coef          = np.corrcoef([row[0] for row in X], [row[1] for row in X])[0, 1]\n",
    "# informative_coef    = np.corrcoef([row[informative_feature_index] for row in X], y)[0, 1]\n",
    "# noninformative_coef = np.corrcoef([row[1 - informative_feature_index] for row in X], y)[0, 1]\n",
    "# print('    Корреляция между информативным и неинформативным признаками:', inter_coef)\n",
    "# print('    Корреляция между информативным признаком и y:', ' '*14, informative_coef)\n",
    "# print('    Корреляция между неинформативным признаком и y:', ' '*12, noninformative_coef)\n",
    "\n",
    "# 3. Экстрагируем информативный признак, и регрессируем y на неинформативный признак:\n",
    "new_X = np.delete(X, informative_feature_index, 1)\n",
    "statsmodels_result = sm.OLS(y, sm.add_constant(new_X)).fit()\n",
    "print(FONT_BOLD, '\\n\\n -- Построена модель (на основании неинформативного признака).', FONT_END)\n",
    "print('    Оценки коэффициентов регрессии:\\n\\t· Оценка β0:', statsmodels_result.params[0], \n",
    "      '\\n\\t· Оценка β1:', statsmodels_result.params[1])\n",
    "\n",
    "b1_estimate = statsmodels_result.params[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчёт в сторонке: рассчитаем значение оценки β1 по формуле:\n",
    "\n",
    "$$\\hat{\\beta_1}=\\frac{\\text{Cov(X, Y)}}{\\text{Var[X]}}$$\n",
    "\n",
    "БЕЗ ШУМА:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  -- Сгенерирована целевая функция.\n",
      " \u001b[0m     Значения коэффициентов целевой функции:\n",
      "\t· β0 = 4.5 \n",
      "\t· β1 = 71.63019144014122\n",
      "71.6373551757\n",
      "71.6301914401\n"
     ]
    }
   ],
   "source": [
    "NOISE = 0\n",
    "\n",
    "X, y, real_coef = make_regression(n_samples=POPULATION_SIZE, n_features=1, n_informative=1, \n",
    "                                  coef=True, noise=NOISE, bias=BIAS)\n",
    "print(FONT_BOLD, ' -- Сгенерирована целевая функция.\\n', FONT_END, '    Значения коэффициентов целевой функции:')\n",
    "print('\\t· β0 =', BIAS, '\\n\\t· β1 =', real_coef.item(0))\n",
    "\n",
    "cov = np.cov(X[:, 0], y)[0, 1]\n",
    "var = np.var(X[:, 0])\n",
    "print(cov/var)\n",
    "\n",
    "numerator = np.dot(X[:, 0] - np.mean(X), y - np.mean(y))\n",
    "denominator = np.square( np.linalg.norm(X[:, 0]-np.mean(X)) )\n",
    "print(numerator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С ШУМОМ:\n",
    "\n",
    "$$\\hat{\\beta_1}=\\frac{\\text{Cov(X, Y) - Cov(X, E)}}{\\text{Var[X]}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      " Сгенерирована целевая функция.\n",
      "    Значения коэффициентов целевой функции:\n",
      "\t· β0 = 4.5 \n",
      "\t· β1 = 90.0373971821571\n",
      "    Матожидание шума E[epsilon] = 1.53395787951 ≠ 0\n",
      "    Энергия шума   Var[epsilon] = 0.0825474245225\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      " Произведена подгонка модели.\n",
      "\t· Оценка β0: -119.166008222\n",
      "\t· Оценка β1: 80.7718585782\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      " Выполнены рассчёты.\n",
      "\tОценка β1 на чистых данных  : 90.0373971821571\n",
      "\tОценка β1 на шумных данных  : 80.7718585782\n",
      "\tРазность оценок             : -9.26553860395\n",
      "\tДисперсия оценки в присутствии шума (Х чистые): 0.00113663453138\n",
      "\tСпрогнозированная разность 1: 0.00119690263239\n",
      "\tСпрогнозированная разность 2: 0.103947139698\n"
     ]
    }
   ],
   "source": [
    "PRINT_LINE = '-'*80 + '\\n'\n",
    "\n",
    "NOISE = 0\n",
    "BIAS  = 4.5\n",
    "POPULATION_SIZE = 100\n",
    "\n",
    "X, y, real_coef = make_regression(n_samples=POPULATION_SIZE, n_features=1, n_informative=1, \n",
    "                                  coef=True, noise=0, bias=BIAS)\n",
    "print(PRINT_LINE, 'Сгенерирована целевая функция.\\n    Значения коэффициентов целевой функции:')\n",
    "print('\\t· β0 =', BIAS, '\\n\\t· β1 =', real_coef.item(0))\n",
    "\n",
    "# Добавим шум вручную!!\n",
    "NOISE   = 0.2\n",
    "epsilon = np.random.uniform(5, 10, len(X))\n",
    "epsilon = (epsilon*NOISE).reshape(-1, 1)\n",
    "noisy_X = X + epsilon\n",
    "print('    Матожидание шума E[epsilon] =', np.mean(epsilon), '≠ 0')\n",
    "print('    Энергия шума   Var[epsilon] =', np.var(epsilon))\n",
    "#noisy_X   = np.append(X, epsilon, axis=1) # for another experiment\n",
    "\n",
    "# Произведём подгонку модели к зашумлённой версии X::\n",
    "statsmodels_result = sm.OLS(y, sm.add_constant(noisy_X)).fit()\n",
    "print('\\n', PRINT_LINE, 'Произведена подгонка модели.\\n\\t· Оценка β0:', statsmodels_result.params[0])\n",
    "print('\\t· Оценка β1:', statsmodels_result.params[1])\n",
    "\n",
    "# Выполним рассчёты:\n",
    "print('\\n', PRINT_LINE, 'Выполнены рассчёты.')\n",
    "print('\\tОценка β1 на чистых данных  :', real_coef.item(0))\n",
    "print('\\tОценка β1 на шумных данных  :', statsmodels_result.params[1])\n",
    "print('\\tРазность оценок             :', statsmodels_result.params[1]-real_coef.item(0))\n",
    "print('\\tДисперсия оценки в присутствии шума (Х чистые):', np.var(epsilon) / np.square(np.linalg.norm(X-np.mean(X))))\n",
    "\n",
    "cov_XE = np.cov(X[:, 0], epsilon[:, 0])[0, 1]\n",
    "var    = np.var(X[:, 0])\n",
    "print('\\tСпрогнозированная разность 1:', cov_XE/var)\n",
    "\n",
    "cov_XE = np.cov(noisy_X[:, 0], epsilon[:, 0])[0, 1]\n",
    "var    = np.var(noisy_X[:, 0])\n",
    "print('\\tСпрогнозированная разность 2:', cov_XE/var)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cov_XY = np.cov(X[:, 0], y)[0, 1]\n",
    "# cov_XE = np.cov(X[:, 0], epsilon[:, 0])[0, 1]\n",
    "# var    = np.var(X[:, 0])\n",
    "# print('Рассчёт по \"шумной\" формуле:    b1 =?=', (cov_XY - cov_XE)/var)\n",
    "# b1_bias = cov_XE/var\n",
    "# print('\\tПри смещение (в формуле) оценки составляет =', b1_bias)\n",
    "# #print('\\tЗа вычетом второй части получим =', cov_XY/var - second_part)\n",
    "\n",
    "# cov = np.cov(X[:, 0], y)[0, 1]\n",
    "# var = np.var(X[:, 0])\n",
    "# print('\\tКорректировка смещения:', cov/var - b1_bias)\n",
    "# print('Рассчёт по \"бесшумной\" формуле: b1 =?=', cov/var)\n",
    "\n",
    "# numerator = np.dot(X[:, 0] - np.mean(X), y - np.mean(y))\n",
    "# denominator = np.square( np.linalg.norm(X[:, 0]-np.mean(X)) )\n",
    "# print('Рассчёт по длинной \"бесшумной\" формуле: b1 =?=', numerator / denominator)\n",
    "# print('Подсчитанное матожидание резидуалов:', np.mean(statsmodels_result.resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9813305])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------------------------------------------------------\n",
      " influence of epsilon: -11.1316380978\n"
     ]
    }
   ],
   "source": [
    "statsmodels_result2 = sm.OLS(y, sm.add_constant(epsilon)).fit()\n",
    "print('\\n', PRINT_LINE, 'influence of epsilon:', statsmodels_result2.params[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      " Сгенерирована целевая функция.\n",
      "    Значения коэффициентов целевой функции:\n",
      "\t· β0 = 4.5 \n",
      "\t· β1 = 65.9861569425232\n",
      "    Матожидание шума E[epsilon] = 3.06583673417 ≠ 0\n",
      "    Энергия шума   Var[epsilon] = 0.36739023191\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      " Произведена подгонка модели.\n",
      "\t· Оценка β0: -142.041656272\n",
      "\t· Оценка β1: 47.8035142771\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      " Выполняются рассчёты:\n",
      "Рассчёт по \"шумной\" формуле:    b1 =?= 48.0080423192\n",
      "\tПри смещение (в формуле) оценки составляет = 0.278335738488\n",
      "\tКорректировка смещения: 48.0080423192\n",
      "Рассчёт по \"бесшумной\" формуле: b1 =?= 48.2863780577\n",
      "Рассчёт по длинной \"бесшумной\" формуле: b1 =?= 47.8035142771\n",
      "Подсчитанное матожидание резидуалов: 5.82645043323e-15\n"
     ]
    }
   ],
   "source": [
    "### OLDER\n",
    "\n",
    "\n",
    "\n",
    "PRINT_LINE = '-'*80 + '\\n'\n",
    "\n",
    "NOISE = 0\n",
    "POPULATION_SIZE = 100\n",
    "\n",
    "X, y, real_coef = make_regression(n_samples=POPULATION_SIZE, n_features=1, n_informative=1, \n",
    "                                  coef=True, noise=NOISE, bias=BIAS)\n",
    "print(PRINT_LINE, 'Сгенерирована целевая функция.\\n    Значения коэффициентов целевой функции:')\n",
    "print('\\t· β0 =', BIAS, '\\n\\t· β1 =', real_coef.item(0))\n",
    "\n",
    "# Добавим шум вручную!!\n",
    "NOISE   = 0.4\n",
    "epsilon = np.random.uniform(5, 10, len(X))\n",
    "epsilon = (epsilon*NOISE).reshape(-1, 1)\n",
    "print('    Матожидание шума E[epsilon] =', np.mean(epsilon), '≠ 0')\n",
    "print('    Энергия шума   Var[epsilon] =', np.var(epsilon))\n",
    "X = X + epsilon\n",
    "#new_X   = np.append(X, epsilon, axis=1)\n",
    "\n",
    "# Произведём подгонку:\n",
    "statsmodels_result = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "print('\\n', PRINT_LINE, 'Произведена подгонка модели.\\n\\t· Оценка β0:', statsmodels_result.params[0])\n",
    "print('\\t· Оценка β1:', statsmodels_result.params[1])\n",
    "\n",
    "# Выполним рассчёты:\n",
    "print('\\n', PRINT_LINE, 'Выполняются рассчёты:')\n",
    "\n",
    "cov_XY = np.cov(X[:, 0], y)[0, 1]\n",
    "cov_XE = np.cov(X[:, 0], epsilon[:, 0])[0, 1]\n",
    "var    = np.var(X[:, 0])\n",
    "print('Рассчёт по \"шумной\" формуле:    b1 =?=', (cov_XY - cov_XE)/var)\n",
    "b1_bias = cov_XE/var\n",
    "print('\\tПри смещение (в формуле) оценки составляет =', b1_bias)\n",
    "#print('\\tЗа вычетом второй части получим =', cov_XY/var - second_part)\n",
    "\n",
    "cov = np.cov(X[:, 0], y)[0, 1]\n",
    "var = np.var(X[:, 0])\n",
    "print('\\tКорректировка смещения:', cov/var - b1_bias)\n",
    "print('Рассчёт по \"бесшумной\" формуле: b1 =?=', cov/var)\n",
    "\n",
    "numerator = np.dot(X[:, 0] - np.mean(X), y - np.mean(y))\n",
    "denominator = np.square( np.linalg.norm(X[:, 0]-np.mean(X)) )\n",
    "print('Рассчёт по длинной \"бесшумной\" формуле: b1 =?=', numerator / denominator)\n",
    "print('Подсчитанное матожидание резидуалов:', np.mean(statsmodels_result.resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.008042319211995"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48.2863780577 - 0.278335738488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased b1 estimate: -0.3667157829263108\n",
      "Absolute difference: 0.2227956703034174\n"
     ]
    }
   ],
   "source": [
    "informative_beta     = max(real_coef.item(0), real_coef.item(1))\n",
    "non_informative_beta = min(real_coef.item(0), real_coef.item(1))\n",
    "\n",
    "x = X[:, informative_feature_index]\n",
    "z = X[:, 1-informative_feature_index]\n",
    "\n",
    "# Длинная запись:\n",
    "# xz_dot = np.dot(x, z)                  # 1st term\n",
    "# z_mean_x = z*np.mean(x)\n",
    "# z_mean_x = sum(z_mean_x)               # 2nd term\n",
    "# norm_x = (np.linalg.norm(x))**2        # 3rd term\n",
    "# n_mean_x_sq = len(x) * (np.mean(x))**2 # 4th term\n",
    "# b1_biased_estimate = non_informative_beta + informative_beta*((xz_dot-z_mean_x) / (norm_x+n_mean_x_sq))\n",
    "# print(':::', non_informative_beta + informative_beta*((xz_dot-z_mean_x) / (norm_x+n_mean_x_sq)))\n",
    "\n",
    "# Короткая запись:\n",
    "numerator   = np.dot(np.array(x)-np.mean(x), z)\n",
    "denominator = np.square(np.linalg.norm(x)) - len(x)*np.square(np.mean(x)) \n",
    "b1_biased_estimate = non_informative_beta + informative_beta*(numerator/denominator)\n",
    "\n",
    "print('Biased b1 estimate:', b1_biased_estimate)\n",
    "print('Absolute difference:', np.abs(b1_estimate - b1_biased_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2]) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the estimated coefficient b would pick up the effect of x on y plus the association of x and z times the effect of z on y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# z_X = np.delete(X, informative_feature_index, 1)\n",
    "# statsmodels_result = sm.OLS(y, sm.add_constant(z_X)).fit()\n",
    "# print('Effect of NON-INFORMATIVE on y:\\n\\tWith bias:', statsmodels_result.params[1])\n",
    "# statsmodels_result = sm.OLS(y, z_X).fit()\n",
    "# print('\\tNo bias:  ', statsmodels_result.params[0])\n",
    "\n",
    "# z_X = np.delete(X, 1-informative_feature_index, 1)\n",
    "# statsmodels_result = sm.OLS(y, sm.add_constant(z_X)).fit()\n",
    "# print('\\nEffect of INFORMATIVE on y:\\n\\tWith bias:', statsmodels_result.params[1])\n",
    "# statsmodels_result = sm.OLS(y, z_X).fit()\n",
    "# print('\\tNo bias:  ', statsmodels_result.params[0])\n",
    "\n",
    "\n",
    "# z_X_1, z_X_2 = X[informative_feature_index], X[1 - informative_feature_index]\n",
    "# statsmodels_result = sm.OLS(z_X_2, sm.add_constant(z_X_1)).fit()\n",
    "# print('\\nEffect of NON-INFORMATIVE on INFORMATIVE:\\n\\tWith bias:', statsmodels_result.params[1])\n",
    "# statsmodels_result = sm.OLS(z_X_2, z_X_1).fit()\n",
    "# print('\\tNo bias:  ', statsmodels_result.params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.70170091, -1.85892225],\n",
       "       [ 0.08731626, -0.73426896]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10554504703150308"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noninformative_coef + (inter_coef * informative_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.300331078998826"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.76683487328 + (-0.073345030119 * 20.9079770399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(a)\n",
    "a[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**\n",
    "* MSE на тренировочной выборке ожидаемо получилась практически нулевой, в силу того, что подгонка полинома второй степени к двум точкам всегда будет идеальной.\n",
    "* Однако на популяции MSE ожидаемо оказалась выше, с мощной дисперсией. Это обусловлено тем, что через две точки можно провести бесконечное количество парабол, и какая из них будет ближе к целевой функции - абсолютно неизвестно.\n",
    "\n",
    "Теперь проведём такой же опыт, но уберём вариативность, задав как минимум 3 точки для тренировочного набора. Для точного задания параболы необходимо иметь как минимум 3 точки, через которые она проходит; а в силу того, что данные не имеют шума, эти 3 точки всегда будут лежать ровно на целевой параболе. Таким образом, ожидается, что подгонка всегда будет идеальной.\n",
    "\n",
    "<br><br><center>**Опыт 2. Нулевой шум, нулевая вариативность**</center>\n",
    "\n",
    "**Условия:**\n",
    "1. Стохастический шум равен нулю: $\\forall{x}, \\epsilon(x)=0$\n",
    "2. Детерминистский шум равен нулю: $\\mathrm{Complexity}(g)=\\mathrm{Complexity}(f)$\n",
    "3. Вариативность модели нулевая; в данном случае (т.е. в случае с целевой функцией-параболой) объём выборки должен быть $\\geq 3$.\n",
    "\n",
    "**Ожидание:**\n",
    "\n",
    "- Oжидается нулевая MSE как на тренировке, так и на популяции. Это будет достигнуто за счёт нулевой вариативности, нулевого детерминистского и нулевого стохастического шума."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
